[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Kerry Back  J. Howard Creekmore Professor of Finance and Professor of Economics kerryback@gmail.com\n\n\n\nRoom 317, 2:15 – 3:45, 10/23/2023 – 12/4/2023\n\n\n\nThis course provides an introduction to quantitative equity management. Quantitative management means trading on signals that can be constructed and tested on large panels of stocks. The basic elements are: return prediction, correlation prediction, portfolio optimization, and backtesting. One form of quantitative investing is called factor investing or smart beta investing. This has become increasingly popular. For example, momentum is one factor, and etfdb.com recently listed more than 30 equity ETFs based on momentum. In recent years, machine learning methods have been used extensively to find the best combination of factors. Also, many factors have been developed recently from alternative data sources using quantitative methods, including machine-learning based sentiment analysis and image analysis.\nIn the past, many students in this course have not been planning on careers in investment management but instead were mainly interested in gaining more experience in quantitative methods. The course is designed with that in mind. We will spend time discussing machine learning methods and other data analysis topics and learn how to apply the concepts in python. I do not expect you to be proficient in python. The only real requirement is that you know how to open a Jupyter notebook and execute cells.\nChatGPT makes it much easier to use python. Throughout the course, we will generate python code by using ChatGPT either at the OpenAI website or via an extension to VS Code. One skill you will develop in the course is to become a good “prompt engineer.”\n\n\n\n\nOverview of quant investing and software tools\nTime series models and return predictability\nTime series models for pairs trading\nMachine learning for classification\nMachine learning for regression and data pipelines\nNeural networks\nCross validation of hyperparameters\nFactor models for return prediction\nFactor models for risk prediction\nPortfolio optimization\nBacktesting\nReturn attribution\n\n\n\n\nThe course deliverables are weekly individual assignments and a group project. The individual assignments involve submission of Jupyter notebooks. They are primarily intended to ensure that everyone keeps up. For the assignments and for the group project, googling and using ChatGPT are allowed.\nThe group project will involve analyzing a specific data set of signals and returns and testing a quantitative investment strategy using the methods developed in the course. It will require putting things together, but it will not require significant new code development. The project will be assigned the last day of class and will be due a week later. Groups must consist of three or fewer students.\nThe individual assignments will account for half of the course grade. The group project will account for 40%. The remaining 10% will be based on within-group peer evaluations.\n\n\n\nThis course is a prerequisite for a full-semester spring course called Data Driven Investments Lab. It will be co-taught by Kevin Crotty and myself. The lab course will involve students working in groups to explore other data sources and to further elaborate and test strategies. Strategies will be implemented with paper trading at Alpaca, which is a brokerage with a free python API.\n\n\n\nEach year, the Chicago Quantitative Alliance (CQA) hosts a competition for universities on quantitative investing - the CQA Challenge. The JGSB MBA program has a two-year winning streak in the competition, placing first in 2022 and again in 2023. The winning JGSB teams have used machine learning methods for return prediction developed in this course and have generated higher returns than any of the 30 or so other schools in the competition.\nThe competition is to run a diversified long-short market-neutral portfolio with a quantitative approach. Paper trading is done using the StockTrak platform. Teams are judged on compliance, returns, and a video presentation of their strategy in three stages: teams that perform well on compliance proceed to the second stage, the top ten teams on compliance and portfolio returns proceed to the third stage, and teams in the third stage prepare video presentations.\nIf a group participates in the CQA competition, then they can work as a group in the Data-Driven Investments Lab course, and the project in that course can be configured to support participation in the competition. A team in the CQA competition is limited to five persons, but Rice can enter up to three teams. The competition begins in the first part of November. The start date is a little early relative to the timing of our courses, but you could use a generic strategy initially and then later trade into a strategy that you have optimized and tested. The contest lasts until the first of April, and participation entails a commitment until then.\n\n\n\nThe Rice University honor code applies to all work in this course. Each student must do his or her own assignments, but it is allowed and in fact encouraged for students to seek advice from each other. Likewise, groups must do their projects, but they can seek advice from students in other groups. Also, searching for advice on the internet is allowed.\n\n\n\nAny student with a documented disability requiring accommodations in this course is encouraged to contact me outside of class. All discussions will remain confidential. Any adjustments or accommodations regarding assignments or the final exam must be made in advance. Students with disabilities should also contact Disability Support Services in the Allen Center."
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "",
    "section": "",
    "text": "2. Exploratory Data Analysis\n3. Trees\n4. Random Forests\n5. Neural Nets\n6. Transforming Data Features\n7. Validating Hyperparameters\n8. Analyzing Stock Picks\n9. Targets and Industries\n10. Trading"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "",
    "section": "",
    "text": "Download book-to-market (bm) for 2021-12 from the SQL database and compute summary statistics.\nSubmit a jupyter notebook with your code that shows the summary statistics."
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "",
    "section": "",
    "text": "Submit a Jupyter notebook. Copy each question into a Markdown cell and provide your answer in the cell or cells below it.\n\n…"
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "",
    "section": "",
    "text": "Fit a random forest to the 2021-01 data using roeq, mom12m, and bm (book-to-market) as the predictors. Use ret as the target variable (rather than rnk). Set max_depth=4. Compute the in-sample \\(R^2\\) as model.score(X,y).\nSubmit a Jupyter notebook to Ccanvas that contains your code and shows the \\(R^2\\)."
  },
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "",
    "section": "",
    "text": "Get the 2021-12 data: ret, roeq, mom12m, and bm. Define rnk from ret as usual. Create a pipeline with transform1, poly, transform2, and model, where you define the model as MLPRegressor(random_state=0). Define a parameter grid with hidden layer sizes of (16, 8, 4, 2) and (8, 4, 2). Define cv = GridSearchCV, inputting the pipeline and parameter grid. Fit cv to (X, y) where X is roeq, mom12m, and bm from the 2021-12 data and y is rnk from the 2021-12 data. Compute cv.score(X, y) for the same X and y that you fit to. Submit your Jupyter notebook."
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "",
    "section": "",
    "text": "Submit a Jupyter notebook. Copy each question into a Markdown cell and provide your answer in the cell or cells below it.\n\nGet the 2021-12 data for ret, roeq, mom12m, bm, and siccd.\nDefine “industry” using ff49.xlsx.\nDefine the deviations from means (roeqx, mom12mx, bmx) and industry momentum (mom12mi).\nFollow the “without dummies” procedure in 9-targets-and-industries.html except that for the model use GradientBoostingRegressor instead of RandomForestRegressor.\nFor the parameter grid, use\n\n{\n  \"transformedtargetregressor__regressor__max_depth\": [3, 4],\n  \"transformedtargetregressor__regressor__n_estimators\": [500, 1000],\n  \"transformedtargetregressor__regressor__learning_rate\": [0.01, 0.05],\n}\n\nFit the GridSearchCV to\n\nX = data[[\n  \"roeq\",\n  \"mom12m\",\n  \"bm\",\n  \"roeqx\",\n  \"mom12mx\",\n  \"bmx\",\n  \"mom12mi\"\n]]\ny = data[\"ret\"]\n\nOutput cv.best_params_\nRepeat #1–#3 for the 2022-01 data.\nCalculate X and y for the 2022-01 data as in #6.\nCalculate cv.score(X, y) for the 2022-01 X and y.\nThe score in #10 will not look good. But run the following code for the 2022-01 data:\n\ndata[\"predict\"] = cv.predict(X)\ndata[\"quintile\"] = pd.qcut(data.predict, 5, labels=range(1, 6))\ndata.groupby(\"quintile\").ret.mean()"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "",
    "section": "",
    "text": "Assignment 2\nAssignment 3\nAssignment 4"
  },
  {
    "objectID": "notebooks.html",
    "href": "notebooks.html",
    "title": "",
    "section": "",
    "text": "3. Trees\n4. Forests\n5. Nets\n6. Transforming Features\n7. Validating Hyperparameters\n8. Analyzing Stock Picks\n9. Targets and Industries\n10. Trading\n11. Backtesting"
  }
]